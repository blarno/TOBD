{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Форматы данных (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. \"Лекция 5: Форматы данных (часть 2)\"\n",
    "* https://docs.python.org/3/library/csv.html\n",
    "* https://docs.h5py.org/en/stable/\n",
    "* Уэс Маккини. Python и анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте данные из файла `open_pubs.csv`, используя `csv.reader`, и преобразуйте к структуре данных следующего вида:\n",
    "    \n",
    "`{'fas_id': [24, 30, ...], 'name': ['Achor Inn', 'Angel Inn', ...], ... }`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['24', 'Anchor Inn', 'Upper Street, Stratford St Mary, COLCHESTER, Essex', 'CO7 6LW', '604748', '234405', '51.97039', '0.979328', 'Babergh']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/open_pubs.csv') as fp:\n",
    "    reader = csv.reader(fp)\n",
    "    header = next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'tag']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Сгенерируйте 2 случайные матрицы размера 10_000 x 10_000 и вычислите их произведение. Сколько времени занимают три этих операции? Сохраните 3 полученных матрицы в файл .npz с соответствующими названиями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.random.randint(0, 100, size=(10000, 10000))\n",
    "B = np.random.randint(0, 100, size=(10000, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('A.npy', A)\n",
    "np.savez('AB.npz', alexandr = A, artem = B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x20fee14a790>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.load('AB.npz')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexandr', 'artem']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 18, 53, ..., 50, 22, 59],\n",
       "       [34, 30, 41, ..., 63, 23, 60],\n",
       "       [10, 86,  9, ..., 92, 96, 88],\n",
       "       ...,\n",
       "       [90, 30, 25, ..., 65, 32,  0],\n",
       "       [14, 69, 53, ...,  0, 61, 38],\n",
       "       [49, 72, 60, ..., 18, 62, 29]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['alexandr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создайте 2 матрицы размера 1000x1000, используя различные параметризируемые распределения из numpy (https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html#distributions)\n",
    "\n",
    "После этого сохраните получившиеся матрицы в hdf5-файл в виде двух различных датасетов. В качестве описания каждого датасета укажите параметры используемых распределений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('test.h5', 'w') as hdf:\n",
    "    ds1 = hdf. create_dataset('arrA', data = A)\n",
    "    ds1.attrs['description'] = 'В этом дотасете хранится массив A'\n",
    "    \n",
    "    ds2 = hdf. create_dataset('arrB', data = B)\n",
    "    ds2.attrs['description'] = 'В этом дотасете хранится массив B'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('test.h5', 'r') as hdf:\n",
    "    ds1 = hdf['arrA']\n",
    "    print(type(ds1))\n",
    "    arr = ds1[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 18, 53, ..., 50, 22, 59],\n",
       "       [34, 30, 41, ..., 63, 23, 60],\n",
       "       [10, 86,  9, ..., 92, 96, 88],\n",
       "       ...,\n",
       "       [25, 15,  6, ..., 94, 78, 95],\n",
       "       [16, 68, 72, ..., 15, 48, 91],\n",
       "       [ 7, 50,  4, ..., 72, 44, 56]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 В файле `tags_sample.csv` находится информация о тэгах, приписываемых рецептам. Воспользовавшись `csv.reader`, считайте этот файл и создайте словарь вида `id_рецепта: [список тэгов]`. Сохраните этот словарь в файл `tags_sample.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weeknight',\n",
       " 'time-to-make',\n",
       " 'course',\n",
       " 'main-ingredient',\n",
       " 'cuisine',\n",
       " 'preparation',\n",
       " 'occasion',\n",
       " 'north-american',\n",
       " 'soups-stews',\n",
       " 'beans',\n",
       " 'poultry',\n",
       " 'american',\n",
       " 'chicken',\n",
       " 'stove-top',\n",
       " 'dietary',\n",
       " 'gluten-free',\n",
       " 'comfort-food',\n",
       " 'californian',\n",
       " 'black-beans',\n",
       " 'free-of-something',\n",
       " 'meat',\n",
       " 'taste-mood',\n",
       " 'equipment',\n",
       " 'grilling',\n",
       " '4-hours-or-less']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "dict_tags = {}\n",
    "ids = []\n",
    "with open('data/tags_sample.csv') as fp:\n",
    "    reader = csv.reader(fp)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        dict_tags.setdefault(row[0],[]).append(row[1])\n",
    "dict_tags['44123']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Считайте файл `recipes_sample_with_filled_nsteps.csv` (__ЛР4__) в виде `pd.DataFrame`. Добавьте к таблице 2 столбца: `n_tags`, содержащий количество тэгов у этого рецепта; и `tags`, содержащий набор тэгов в виде строки (тэги внутри строки разделяются символом `;`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_tags</th>\n",
       "      <th>name</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35193</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "      <td>44123</td>\n",
       "      <td>90</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11</td>\n",
       "      <td>25.0</td>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>weeknight;time-to-make;course;main-ingredient;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91970</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "      <td>67664</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>15-minutes-or-less;time-to-make;course;prepara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1533</td>\n",
       "      <td>these were so go, it surprised even me.</td>\n",
       "      <td>38798</td>\n",
       "      <td>30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>2002-08-29</td>\n",
       "      <td>30-minutes-or-less;time-to-make;course;main-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22724</td>\n",
       "      <td>my sister-in-law made these for us at a family...</td>\n",
       "      <td>35173</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>2002-07-27</td>\n",
       "      <td>60-minutes-or-less;time-to-make;course;prepara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4470</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "      <td>84797</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>30-minutes-or-less;time-to-make;course;main-in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributor_id                                        description     id  \\\n",
       "0           35193  an original recipe created by chef scott meska...  44123   \n",
       "1           91970  my children and their friends ask for my homem...  67664   \n",
       "2            1533            these were so go, it surprised even me.  38798   \n",
       "3           22724  my sister-in-law made these for us at a family...  35173   \n",
       "4            4470  i think a fondue is a very romantic casual din...  84797   \n",
       "\n",
       "   minutes  n_ingredients  n_steps  n_tags  \\\n",
       "0       90           18.0       11    25.0   \n",
       "1       10            NaN        3    31.0   \n",
       "2       30            8.0        5    17.0   \n",
       "3       45            NaN        7    11.0   \n",
       "4       25            NaN        4    19.0   \n",
       "\n",
       "                                       name  submitted  \\\n",
       "0     george s at the cove  black bean soup 2002-10-25   \n",
       "1        healthy for them  yogurt popsicles 2003-07-26   \n",
       "2              i can t believe it s spinach 2002-08-29   \n",
       "3                      italian  gut busters 2002-07-27   \n",
       "4  love is in the air  beef fondue   sauces 2004-02-23   \n",
       "\n",
       "                                                tags  \n",
       "0  weeknight;time-to-make;course;main-ingredient;...  \n",
       "1  15-minutes-or-less;time-to-make;course;prepara...  \n",
       "2  30-minutes-or-less;time-to-make;course;main-in...  \n",
       "3  60-minutes-or-less;time-to-make;course;prepara...  \n",
       "4  30-minutes-or-less;time-to-make;course;main-in...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "recipes = pd.read_csv('data/recipes_sample_with_filled_nsteps.csv',sep = ',',parse_dates=['submitted'])\n",
    "dict_tags_str = {}\n",
    "len_tags = []\n",
    "for i in dict_tags:\n",
    "    dict_tags_str[i] = ';'.join(dict_tags[i])\n",
    "    len_tags.append(len(dict_tags[i]))\n",
    "df_tags = pd.DataFrame.from_dict(dict_tags_str,orient = 'index').reset_index().rename(columns={0:'tags','index':'id'})\n",
    "df_tags['n_tags'] = len_tags\n",
    "recipes = recipes.combine_first(df_tags)\n",
    "recipes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 В файле `ingredients_sample.csv` находится информация о ингредиентах, необходимых для рецепта. Воспользовавшись `csv.DictReader`, считайте этот файл и создайте словарь вида `id_рецепта: [список ингредиентов]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unsalted butter',\n",
       " 'carrot',\n",
       " 'onion',\n",
       " 'celery',\n",
       " 'broccoli stem',\n",
       " 'dried thyme',\n",
       " 'dried oregano',\n",
       " 'dried sweet basil leaves',\n",
       " 'dry white wine',\n",
       " 'chicken stock',\n",
       " 'worcestershire sauce',\n",
       " 'tabasco sauce',\n",
       " 'smoked chicken',\n",
       " 'black beans',\n",
       " 'broccoli floret',\n",
       " 'heavy cream',\n",
       " 'salt & fresh ground pepper',\n",
       " 'cornstarch']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "dict_ingredients = {}\n",
    "with open('data/ingredients_sample.csv') as fp:\n",
    "    reader = csv.DictReader(fp)\n",
    "    for row in reader:\n",
    "        dict_ingredients.setdefault(row['recipe_id'],[]).append(row['ingredient'])\n",
    "dict_ingredients['44123']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Добавьте к таблице из задания 1.2 столбец `ingredients`, содержащий набор ингредиентов в виде строки (ингредиенты внутри строки разделяются символом `*`)\n",
    "\n",
    "Для строк, которые содержат пропуски в столбце `n_ingredients`, заполните их на основе файла  `ingredients_sample.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>minutes</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_tags</th>\n",
       "      <th>name</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35193</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "      <td>44123</td>\n",
       "      <td>unsalted butter*carrot*onion*celery*broccoli s...</td>\n",
       "      <td>90</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11</td>\n",
       "      <td>25.0</td>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>weeknight;time-to-make;course;main-ingredient;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91970</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "      <td>67664</td>\n",
       "      <td>unsalted butter*all-purpose flour*walnuts*ligh...</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>15-minutes-or-less;time-to-make;course;prepara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1533</td>\n",
       "      <td>these were so go, it surprised even me.</td>\n",
       "      <td>38798</td>\n",
       "      <td>unsalted butter*onion*milk*salt*egg*cream chee...</td>\n",
       "      <td>30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>2002-08-29</td>\n",
       "      <td>30-minutes-or-less;time-to-make;course;main-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22724</td>\n",
       "      <td>my sister-in-law made these for us at a family...</td>\n",
       "      <td>35173</td>\n",
       "      <td>unsalted butter*milk*eggs*honey*white bread*va...</td>\n",
       "      <td>45</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>2002-07-27</td>\n",
       "      <td>60-minutes-or-less;time-to-make;course;prepara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4470</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "      <td>84797</td>\n",
       "      <td>unsalted butter*nuts*granulated sugar*semi-swe...</td>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>30-minutes-or-less;time-to-make;course;main-in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributor_id                                        description     id  \\\n",
       "0           35193  an original recipe created by chef scott meska...  44123   \n",
       "1           91970  my children and their friends ask for my homem...  67664   \n",
       "2            1533            these were so go, it surprised even me.  38798   \n",
       "3           22724  my sister-in-law made these for us at a family...  35173   \n",
       "4            4470  i think a fondue is a very romantic casual din...  84797   \n",
       "\n",
       "                                         ingredients  minutes  n_ingredients  \\\n",
       "0  unsalted butter*carrot*onion*celery*broccoli s...       90           18.0   \n",
       "1  unsalted butter*all-purpose flour*walnuts*ligh...       10            6.0   \n",
       "2  unsalted butter*onion*milk*salt*egg*cream chee...       30            8.0   \n",
       "3  unsalted butter*milk*eggs*honey*white bread*va...       45            8.0   \n",
       "4  unsalted butter*nuts*granulated sugar*semi-swe...       25            4.0   \n",
       "\n",
       "   n_steps  n_tags                                      name  submitted  \\\n",
       "0       11    25.0     george s at the cove  black bean soup 2002-10-25   \n",
       "1        3    31.0        healthy for them  yogurt popsicles 2003-07-26   \n",
       "2        5    17.0              i can t believe it s spinach 2002-08-29   \n",
       "3        7    11.0                      italian  gut busters 2002-07-27   \n",
       "4        4    19.0  love is in the air  beef fondue   sauces 2004-02-23   \n",
       "\n",
       "                                                tags  \n",
       "0  weeknight;time-to-make;course;main-ingredient;...  \n",
       "1  15-minutes-or-less;time-to-make;course;prepara...  \n",
       "2  30-minutes-or-less;time-to-make;course;main-in...  \n",
       "3  60-minutes-or-less;time-to-make;course;prepara...  \n",
       "4  30-minutes-or-less;time-to-make;course;main-in...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ingredients_str = {}\n",
    "len_ingredients = []\n",
    "for i in dict_ingredients:\n",
    "    dict_ingredients_str[i] = '*'.join(dict_ingredients[i])\n",
    "    len_ingredients.append(len(dict_ingredients[i]))\n",
    "df_ingredients = pd.DataFrame.from_dict(dict_ingredients_str,orient = 'index').reset_index().rename(columns={0:'ingredients','index':'id'})\n",
    "df_ingredients['n_ingredients'] = len_ingredients\n",
    "recipes = recipes.combine_first(df_ingredients)\n",
    "recipes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Проверьте, содержит ли столбец `n_ingredients` пропуски. Если нет, треобразуйте его к целочисленному типу и сохраните результаты в файл `recipes_sample_with_tags_ingredients.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recipes['n_ingredients'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['n_ingredients'] = recipes['n_ingredients'].astype(int)\n",
    "recipes.to_csv('data/recipes_sample_with_tags_ingredients.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Разделите таблицу, полученную в результате 1.5, на две таблицы: одна содержит рецепты, загруженные до 2000 года; вторая - все остальные. В полученных таблицах оставьте только числовые столбцы и преобразуйте их к `numpy.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr_lower_2000 = recipes[recipes['submitted'].dt.year<2000][['contributor_id','id','minutes','n_ingredients','n_steps','n_tags']].to_numpy()\n",
    "arr_higher_2000 = recipes[recipes['submitted'].dt.year>=2000][['contributor_id','id','minutes','n_ingredients','n_steps','n_tags']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5620e+03, 3.4410e+03, 3.0000e+01, 8.0000e+00, 8.0000e+00,\n",
       "        1.0000e+01],\n",
       "       [1.6170e+03, 4.2050e+03, 2.5000e+01, 5.0000e+00, 3.0000e+00,\n",
       "        1.4000e+01],\n",
       "       [1.5340e+03, 3.2580e+03, 0.0000e+00, 6.0000e+00, 8.0000e+00,\n",
       "        2.0000e+01],\n",
       "       ...,\n",
       "       [1.5350e+03, 3.7520e+03, 0.0000e+00, 4.0000e+00, 1.3000e+01,\n",
       "        9.0000e+00],\n",
       "       [1.5980e+03, 4.8010e+03, 2.0000e+01, 7.0000e+00, 4.0000e+00,\n",
       "        1.8000e+01],\n",
       "       [1.2403e+05, 2.9820e+03, 0.0000e+00, 6.0000e+00, 6.0000e+00,\n",
       "        1.3000e+01]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_lower_2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Сохраните 2 полученных массива в архив `npz`. Дайте массивам читаемые имена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('data/arr.npz',arr_lower_2000=arr_lower_2000,arr_higher_2000=arr_higher_2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Считайте созданный архив и продемонстрируйте, что данные считались корректно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5620e+03, 3.4410e+03, 3.0000e+01, 8.0000e+00, 8.0000e+00,\n",
       "        1.0000e+01],\n",
       "       [1.6170e+03, 4.2050e+03, 2.5000e+01, 5.0000e+00, 3.0000e+00,\n",
       "        1.4000e+01],\n",
       "       [1.5340e+03, 3.2580e+03, 0.0000e+00, 6.0000e+00, 8.0000e+00,\n",
       "        2.0000e+01],\n",
       "       ...,\n",
       "       [1.5350e+03, 3.7520e+03, 0.0000e+00, 4.0000e+00, 1.3000e+01,\n",
       "        9.0000e+00],\n",
       "       [1.5980e+03, 4.8010e+03, 2.0000e+01, 7.0000e+00, 4.0000e+00,\n",
       "        1.8000e+01],\n",
       "       [1.2403e+05, 2.9820e+03, 0.0000e+00, 6.0000e+00, 6.0000e+00,\n",
       "        1.3000e+01]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.load('data/arr.npz')\n",
    "r['arr_lower_2000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выведите названия всех датасетов, находящихся в файле `nutrition_sample.h5`, а также размерность матриц, содержащихся в данных датасетах и их метаданные.\n",
    "\n",
    "Формат вывода:\n",
    "```\n",
    "Dataset name=dataset_0, dataset size=(30000,), metadata={'info': 'calories (#)'}\n",
    "Dataset name=dataset_1, dataset size=(30000,), metadata={'info': 'total fat (PDV)'}\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name=dataset_0, dataset size=(30000, 2), metadata=['recipe_id', 'calories (#)']\n",
      "Dataset name=dataset_1, dataset size=(30000, 2), metadata=['recipe_id', 'total fat (PDV)']\n",
      "Dataset name=dataset_2, dataset size=(30000, 2), metadata=['recipe_id', 'sugar (PDV)']\n",
      "Dataset name=dataset_3, dataset size=(30000, 2), metadata=['recipe_id', 'sodium (PDV)']\n",
      "Dataset name=dataset_4, dataset size=(30000, 2), metadata=['recipe_id', 'protein (PDV)']\n",
      "Dataset name=dataset_5, dataset size=(30000, 2), metadata=['recipe_id', 'saturated fat (PDV)']\n",
      "Dataset name=dataset_6, dataset size=(30000, 2), metadata=['recipe_id', 'carbohydrates (PDV)']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "datasets = []\n",
    "names = []\n",
    "attrs = []\n",
    "with h5py.File('data/nutrition_sample.h5', 'r') as hdf:\n",
    "    for dataset in hdf:\n",
    "        datasets.append(hdf[dataset][:])\n",
    "        names.append(str(dataset))\n",
    "        attrs.append(list(hdf[dataset].attrs.values()))\n",
    "        print('Dataset name=' + str(dataset) + ', dataset size=' + str(hdf[dataset].shape) + ', metadata=' + str(list(hdf[dataset].attrs.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recipe_id', 'calories (#)']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Разбейте каждый из имеющихся датасетов на две части: 1 часть содержит только те строки, где PDV (Percent Daily Value) превышает 100%; 2 часть содержит те строки, где PDV не составляет не более 100%. Создайте 2 группы в файле и разместите в них соответствующие части датасета c сохранением метаданных исходных датасетов. Итого должно получиться 2 группы, содержащие несколько датасетов. Сохраните результаты в файл `nutrition_grouped.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_lower_100 = []\n",
    "datasets_higher_100 = []\n",
    "for dataset in datasets:\n",
    "    datasets_higher_100.append(dataset[dataset[:,1]>100])\n",
    "    datasets_lower_100.append(dataset[dataset[:,1]<=100])\n",
    "with h5py.File('data/nutrition_grouped.h5', 'w') as f:\n",
    "    lower_100 = f.create_group('lower_100')\n",
    "    higher_100 = f.create_group('higher_100')\n",
    "    for i in range(len(names)):\n",
    "        low_100 = lower_100.create_dataset(names[i], data=datasets_lower_100[i])\n",
    "        high_100 = higher_100.create_dataset(names[i], data=datasets_higher_100[i])\n",
    "        low_100.attrs['col_0'] = attrs[i][0]\n",
    "        low_100.attrs['col_1'] = attrs[i][1]\n",
    "        high_100.attrs['col_0'] = attrs[i][0]\n",
    "        high_100.attrs['col_1'] = attrs[i][1]g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Выведите названия всех групп и датасетов, находящихся в этих группах, из файла `nutrition_grouped.h5` а также размерность матриц, содержащихся в датасетах и их метаданные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group=higher_100, Dataset name=dataset_0, dataset size=(26733, 2), metadata=['recipe_id', 'calories (#)']\n",
      "group=higher_100, Dataset name=dataset_1, dataset size=(1736, 2), metadata=['recipe_id', 'total fat (PDV)']\n",
      "group=higher_100, Dataset name=dataset_2, dataset size=(5316, 2), metadata=['recipe_id', 'sugar (PDV)']\n",
      "group=higher_100, Dataset name=dataset_3, dataset size=(1244, 2), metadata=['recipe_id', 'sodium (PDV)']\n",
      "group=higher_100, Dataset name=dataset_4, dataset size=(1776, 2), metadata=['recipe_id', 'protein (PDV)']\n",
      "group=higher_100, Dataset name=dataset_5, dataset size=(2858, 2), metadata=['recipe_id', 'saturated fat (PDV)']\n",
      "group=higher_100, Dataset name=dataset_6, dataset size=(642, 2), metadata=['recipe_id', 'carbohydrates (PDV)']\n",
      "group=lower_100, Dataset name=dataset_0, dataset size=(3267, 2), metadata=['recipe_id', 'calories (#)']\n",
      "group=lower_100, Dataset name=dataset_1, dataset size=(28264, 2), metadata=['recipe_id', 'total fat (PDV)']\n",
      "group=lower_100, Dataset name=dataset_2, dataset size=(24684, 2), metadata=['recipe_id', 'sugar (PDV)']\n",
      "group=lower_100, Dataset name=dataset_3, dataset size=(28756, 2), metadata=['recipe_id', 'sodium (PDV)']\n",
      "group=lower_100, Dataset name=dataset_4, dataset size=(28224, 2), metadata=['recipe_id', 'protein (PDV)']\n",
      "group=lower_100, Dataset name=dataset_5, dataset size=(27142, 2), metadata=['recipe_id', 'saturated fat (PDV)']\n",
      "group=lower_100, Dataset name=dataset_6, dataset size=(29358, 2), metadata=['recipe_id', 'carbohydrates (PDV)']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('data/nutrition_grouped.h5', 'r') as hdf:\n",
    "    for group in hdf:\n",
    "        for dataset in hdf[group]:\n",
    "            print('group=' + str(group) + ', Dataset name=' + str(dataset) + ', dataset size=' + str(hdf[group][dataset].shape) + ', metadata=' + str(list(hdf[group][dataset].attrs.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Модифицируйте код из 3.3 таким образом, чтобы сохранить датасеты, используя сжатие. Сравните размер полученного файла с размерами файла из 3.3. Прокомментируйте результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/nutrition_grouped_compressed.h5', 'w') as f:\n",
    "    lower_100 = f.create_group('lower_100')\n",
    "    higher_100 = f.create_group('higher_100')\n",
    "    for i in range(len(names)):\n",
    "        low_100 = lower_100.create_dataset(names[i], data=datasets_lower_100[i],compression=\"gzip\")\n",
    "        high_100 = higher_100.create_dataset(names[i], data=datasets_higher_100[i],compression=\"gzip\")\n",
    "        low_100.attrs['col_0'] = attrs[i][0]\n",
    "        low_100.attrs['col_1'] = attrs[i][1]\n",
    "        high_100.attrs['col_0'] = attrs[i][0]\n",
    "        high_100.attrs['col_1'] = attrs[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Без сжатия 3290кб\n",
    "#Со сжатием 1158кб -> очевидно объем меньше"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
